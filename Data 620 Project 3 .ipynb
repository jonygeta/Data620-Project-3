{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender Name Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import names\n",
    "from nltk.metrics.scores import (precision, recall)\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "[(name, 'female') for name in names.words('female.txt')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "random.shuffle(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Peggie', 'female'),\n",
       " ('Solange', 'female'),\n",
       " ('Rana', 'female'),\n",
       " ('Jessy', 'female'),\n",
       " ('Lelia', 'female'),\n",
       " ('Dorothy', 'female'),\n",
       " ('Ulrick', 'male'),\n",
       " ('Roshelle', 'female'),\n",
       " ('Caitrin', 'female')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data set into train test set, test-dev set and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7944"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = names[0:500]\n",
    "dev_test_set = names[501:1001]\n",
    "training_set = names[1001:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6943"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Name Gender Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'name_length':len(word),'first_letter':word[1],'last_letter': word[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(gender_features(n), g) for (n,g) in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = featuresets[0:500]\n",
    "dev_test_set = featuresets[501:1001]\n",
    "train_set = featuresets[1001:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print (nltk.classify.accuracy(classifier, dev_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy with only name length, first letter and last letter is 0.774."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     33.3 : 1.0\n",
      "             last_letter = 'k'              male : female =     29.2 : 1.0\n",
      "             last_letter = 'p'              male : female =     18.6 : 1.0\n",
      "             last_letter = 'f'              male : female =     15.2 : 1.0\n",
      "             last_letter = 'v'              male : female =      9.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features[\"firstletter\"] = name[0].lower()\n",
    "    features[\"lastletter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count(%s) \"%letter] = name.lower().count(letter)\n",
    "        features[\"has(%s)\"%letter] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'name_length': 8, 'first_letter': 'e', 'last_letter': 'd'}, 'male'),\n",
       " ({'name_length': 6, 'first_letter': 'l', 'last_letter': 'e'}, 'female'),\n",
       " ({'name_length': 7, 'first_letter': 'n', 'last_letter': 'l'}, 'female'),\n",
       " ({'name_length': 8, 'first_letter': 'a', 'last_letter': 'e'}, 'male'),\n",
       " ({'name_length': 5, 'first_letter': 'a', 'last_letter': 'y'}, 'female'),\n",
       " ({'name_length': 3, 'first_letter': 'a', 'last_letter': 'm'}, 'female'),\n",
       " ({'name_length': 9, 'first_letter': 'a', 'last_letter': 'e'}, 'female'),\n",
       " ({'name_length': 5, 'first_letter': 'e', 'last_letter': 'a'}, 'female'),\n",
       " ({'name_length': 6, 'first_letter': 'u', 'last_letter': 'n'}, 'male')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_test_set[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(gender_features2(n), g) for (n,g) in names]\n",
    "test_set = featuresets[0:500]\n",
    "dev_test_set = featuresets[501:1001]\n",
    "train_set = featuresets[1001:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print( nltk.classify.accuracy(classifier, dev_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'suffix1': word[-1:],'suffix2': word[-2:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = names[1500:]\n",
    "devtest_names = names[500:1500]\n",
    "test_names = names[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.791\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features(n), g) for (n,g) in train_names]\n",
    "devtest_set = [(gender_features(n), g) for (n,g) in devtest_names]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print (nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Incremental improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "### With first last letter prefix and suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_features1(name):\n",
    "    features = {}\n",
    "    name_holder = name\n",
    "    features[\"first_letter\"] = name[0].lower() \n",
    "    features[\"last_letter\"] = name[-1].lower() \n",
    "    features[\"prefix\"] = name[:3].lower() if len(name) > 4 else name[:2].lower() \n",
    "    features[\"suffix\"] = name[-3:].lower() if len(name) > 4 else name[-2:].lower()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.834\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(naive_features1(n), g) for (n,g) in names]\n",
    "test_set = featuresets[0:500]\n",
    "dev_test_set = featuresets[501:1001]\n",
    "train_set = featuresets[1001:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print( nltk.classify.accuracy(classifier, dev_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding last vowels with previous model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_features2(name):\n",
    "    features = {}\n",
    "    name_holder = name\n",
    "    features[\"first_letter\"] = name[0].lower() \n",
    "    features[\"last_letter\"] = name[-1].lower() \n",
    "    features[\"prefix\"] = name[:3].lower() if len(name) > 4 else name[:2].lower() \n",
    "    features[\"suffix\"] = name[-3:].lower() if len(name) > 4 else name[-2:].lower()\n",
    "    features['last_vowel']= (name[-1] in 'aeiou')\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.828\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(naive_features2(n), g) for (n,g) in names]\n",
    "test_set = featuresets[0:500]\n",
    "dev_test_set = featuresets[501:1001]\n",
    "train_set = featuresets[1001:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print( nltk.classify.accuracy(classifier, dev_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy with first letter, last letter, prefix , suffix and last vowel is 0.828 which is less than the previous naive bayes classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last vowel doesn't help much ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking clustering into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_features3(name):\n",
    "    features = {}\n",
    "    name_holder = name\n",
    "    eng_constants = [\"bl\", \"br\", \"ch\", \"cl\", \"cr\", \"dr\", \"fl\", \"fr\", \"gl\", \"gr\", \"pl\", \"pr\", \"sc\", \"sh\", \"sk\", \"sl\", \"sm\", \"sn\", \"sp\", \"st\", \"sw\", \"th\", \"tr\", \"tw\", \"wh\", \"wr\", \"sch\", \"scr\", \"shr\", \"sph\", \"spl\", \"spr\", \"squ\", \"str\", \"thr\"]\n",
    "    features[\"first_letter\"] = name[0].lower() \n",
    "    features[\"last_letter\"] = name[-1].lower() \n",
    "    features[\"prefix\"] = name[:3].lower() if len(name) > 4 else name[:2].lower() \n",
    "    features[\"suffix\"] = name[-3:].lower() if len(name) > 4 else name[-2:].lower()\n",
    "    clusters = []\n",
    "    for cluster in eng_constants[::-1]:\n",
    "        if cluster in name_holder:\n",
    "            name_holder = name_holder.replace(cluster, \"\")\n",
    "            clusters.append(cluster)\n",
    "    features[\"clusters1\"] = clusters[0] if len(clusters) > 0 else None\n",
    "    features[\"clusters2\"] = clusters[1] if len(clusters) > 1 else None\n",
    "    features[\"clusters3\"] = clusters[2] if len(clusters) > 2 else None\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.836\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(naive_features3(n), g) for (n,g) in names]\n",
    "test_set = featuresets[0:500]\n",
    "dev_test_set = featuresets[501:1001]\n",
    "train_set = featuresets[1001:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print( nltk.classify.accuracy(classifier, dev_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy with first letter, last letter, prefix , suffix and constant clustering is 0.836 which is higher than the previous naive bayes classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use constant clustering in the final model as a feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding number of syllabal feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllable(word):\n",
    "    word = word.lower()\n",
    "    vowels = 'aeiouy'\n",
    "\n",
    "    count = 0\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for i in range(1, len(word)):\n",
    "        if word[i] in vowels and word[i-1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith('e'):\n",
    "        count -= 1\n",
    "    elif word.endswith('le'):\n",
    "        count += 1\n",
    "    elif word.endswith('bile'):\n",
    "        count -= 1\n",
    "    elif count == 0:\n",
    "        count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_features4(name):\n",
    "    features = {}\n",
    "    name_holder = name\n",
    "    eng_constants = [\"bl\", \"br\", \"ch\", \"cl\", \"cr\", \"dr\", \"fl\", \"fr\", \"gl\", \"gr\", \"pl\", \"pr\", \"sc\", \"sh\", \"sk\", \"sl\", \"sm\", \"sn\", \"sp\", \"st\", \"sw\", \"th\", \"tr\", \"tw\", \"wh\", \"wr\", \"sch\", \"scr\", \"shr\", \"sph\", \"spl\", \"spr\", \"squ\", \"str\", \"thr\"]\n",
    "    features[\"first_letter\"] = name[0].lower() \n",
    "    features[\"last_letter\"] = name[-1].lower() \n",
    "    features[\"prefix\"] = name[:3].lower() if len(name) > 4 else name[:2].lower() \n",
    "    features[\"suffix\"] = name[-3:].lower() if len(name) > 4 else name[-2:].lower()\n",
    "    clusters = []\n",
    "    for cluster in eng_constants[::-1]:\n",
    "        if cluster in name_holder:\n",
    "            name_holder = name_holder.replace(cluster, \"\")\n",
    "            clusters.append(cluster)\n",
    "    features[\"clusters1\"] = clusters[0] if len(clusters) > 0 else None\n",
    "    features[\"clusters2\"] = clusters[1] if len(clusters) > 1 else None\n",
    "    features[\"clusters3\"] = clusters[2] if len(clusters) > 2 else None\n",
    "    features['syllable_count'] = count_syllable(name)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(naive_features4(n), g) for (n,g) in names]\n",
    "test_set = featuresets[0:500]\n",
    "dev_test_set = featuresets[501:1001]\n",
    "train_set = featuresets[1001:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print( nltk.classify.accuracy(classifier, dev_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most informative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('last_letter', 'a'),\n",
       " ('last_letter', 'k'),\n",
       " ('suffix', 'ard'),\n",
       " ('suffix', 'tta'),\n",
       " ('suffix', 'ita'),\n",
       " ('suffix', 'nne'),\n",
       " ('last_letter', 'p'),\n",
       " ('suffix', 'old'),\n",
       " ('last_letter', 'f'),\n",
       " ('suffix', 'na')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting syllable improves accuracy. So we'll consider number of syllable a important feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm satisifed with the accuracy of the model. The features i've selected are first_letter, last_letter, prefix, suffix, clustering of constants, syllable count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842\n"
     ]
    }
   ],
   "source": [
    "print( nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?Â "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of test and training set are same. The model performs same on the dev-test and test set. We can say that the model is a good fitted model.\n",
    "This is exactly what I've expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
